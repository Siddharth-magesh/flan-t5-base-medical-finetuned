{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a12e5d0d38746c1bf884d0dd7b8fdda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3512 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Context', 'Response'],\n",
      "        num_rows: 3512\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset to inspect available splits\n",
    "dataset = load_dataset('Amod/mental_health_counseling_conversations')\n",
    "\n",
    "# Print available splits\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data saved to train_data.csv\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train']\n",
    "train_df = train_dataset.to_pandas()\n",
    "train_df.to_csv('train_data.csv', index=False)\n",
    "print(\"Train data saved to train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create the formatted prompt\n",
    "def create_prompt(row):\n",
    "    return f\"###Question : {row['Context']} ###Answer : {row['Response']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['text'] = train_df.apply(create_prompt, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['Context', 'Response'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = train_df.head(2809)\n",
    "testing_dataset = train_df[2809:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and test data saved\n"
     ]
    }
   ],
   "source": [
    "training_dataset.to_csv('training_dataset.csv', index=False)\n",
    "testing_dataset.to_csv('testing_dataset.csv', index=False)\n",
    "print(\"Train and test data saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "hf_train  = Dataset.from_pandas(training_dataset)\n",
    "hf_test = Dataset.from_pandas(testing_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 2809\n",
      "}) Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 703\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(hf_train,hf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import FullyShardedDataParallelPlugin, Accelerator\n",
    "from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n",
    "\n",
    "fsdp_plugin = FullyShardedDataParallelPlugin(\n",
    "    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    "    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    ")\n",
    "\n",
    "accelerator = Accelerator(fsdp_plugin=fsdp_plugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    }
   ],
   "source": [
    "import wandb, os\n",
    "wandb.login()\n",
    "\n",
    "wandb_project = \"medical-finetune\"\n",
    "if len(wandb_project) > 0:\n",
    "    os.environ[\"WANDB_PROJECT\"] = wandb_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dfe77e6d6934bc594b3bec009ded22a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cac24772d15458cb15b0d31aebba1ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89e34a6081ee4f808a05cb6514bff56b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, BitsAndBytesConfig ,AutoTokenizer\n",
    "\n",
    "base_model_id = \"google/flan-t5-base\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(base_model_id, quantization_config=bnb_config, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18f87f8e799645848bcc3c456ad3eba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "107db81954fd4d968fa1c7ceca893a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601615a922c94a9996acf1bde7768b01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd2e1c6ff39349eb933999f70aaeb450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def generate_and_tokenize_prompt(prompt):\n",
    "    return tokenizer(create_prompt(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3512\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x900 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset):\n",
    "    lengths = [len(x['text']) for x in tokenized_train_dataset]\n",
    "    lengths += [len(x['text']) for x in tokenized_val_dataset]\n",
    "    print(len(lengths))\n",
    "\n",
    "    # Plotting the histogram\n",
    "    plt.figure(figsize=(15, 9))\n",
    "    plt.hist(lengths, bins=100, alpha=0.7, color='blue')\n",
    "    plt.xlabel('Length of input_ids')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Lengths of input_ids')\n",
    "    plt.show()\n",
    "\n",
    "plot_data_lengths(hf_train, hf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 1000 # This was an appropriate max length for my dataset\n",
    "\n",
    "def generate_and_tokenize_prompt2(example):\n",
    "    result = tokenizer(\n",
    "        example['text'],\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01f54d1dcd3b4ba08ed1a6588d1be33b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2809 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb9bf79b622f43eca23a9b3742722805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/703 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = hf_train.map(generate_and_tokenize_prompt2)\n",
    "tokenized_val_dataset = hf_test.map(generate_and_tokenize_prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 2809\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5ForConditionalGeneration(\n",
      "  (shared): Embedding(32128, 768)\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 768)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 12)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear4bit(in_features=768, out_features=2048, bias=False)\n",
      "              (wi_1): Linear4bit(in_features=768, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-11): 11 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear4bit(in_features=768, out_features=2048, bias=False)\n",
      "              (wi_1): Linear4bit(in_features=768, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (decoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 768)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 12)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear4bit(in_features=768, out_features=2048, bias=False)\n",
      "              (wi_1): Linear4bit(in_features=768, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-11): 11 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear4bit(in_features=768, out_features=2048, bias=False)\n",
      "              (wi_1): Linear4bit(in_features=768, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 13565952 || all params: 180927744 || trainable%: 7.497994337452193\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\n",
    "        \"q\",\n",
    "        \"k\",\n",
    "        \"v\",\n",
    "        \"o\",\n",
    "        \"wi_0\",\n",
    "        \"wi_1\",\n",
    "        \"wo\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.05,  # Conventional\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): T5ForConditionalGeneration(\n",
      "      (shared): Embedding(32128, 768)\n",
      "      (encoder): T5Stack(\n",
      "        (embed_tokens): Embedding(32128, 768)\n",
      "        (block): ModuleList(\n",
      "          (0): T5Block(\n",
      "            (layer): ModuleList(\n",
      "              (0): T5LayerSelfAttention(\n",
      "                (SelfAttention): T5Attention(\n",
      "                  (q): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (k): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (v): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (o): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (relative_attention_bias): Embedding(32, 12)\n",
      "                )\n",
      "                (layer_norm): T5LayerNorm()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (1): T5LayerFF(\n",
      "                (DenseReluDense): T5DenseGatedActDense(\n",
      "                  (wi_0): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=768, out_features=2048, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=2048, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (wi_1): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=768, out_features=2048, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=2048, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (wo): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=2048, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=2048, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (act): NewGELUActivation()\n",
      "                )\n",
      "                (layer_norm): T5LayerNorm()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1-11): 11 x T5Block(\n",
      "            (layer): ModuleList(\n",
      "              (0): T5LayerSelfAttention(\n",
      "                (SelfAttention): T5Attention(\n",
      "                  (q): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (k): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (v): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (o): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                )\n",
      "                (layer_norm): T5LayerNorm()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (1): T5LayerFF(\n",
      "                (DenseReluDense): T5DenseGatedActDense(\n",
      "                  (wi_0): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=768, out_features=2048, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=2048, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (wi_1): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=768, out_features=2048, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=2048, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (wo): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=2048, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=2048, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (act): NewGELUActivation()\n",
      "                )\n",
      "                (layer_norm): T5LayerNorm()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (final_layer_norm): T5LayerNorm()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (decoder): T5Stack(\n",
      "        (embed_tokens): Embedding(32128, 768)\n",
      "        (block): ModuleList(\n",
      "          (0): T5Block(\n",
      "            (layer): ModuleList(\n",
      "              (0): T5LayerSelfAttention(\n",
      "                (SelfAttention): T5Attention(\n",
      "                  (q): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (k): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (v): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (o): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (relative_attention_bias): Embedding(32, 12)\n",
      "                )\n",
      "                (layer_norm): T5LayerNorm()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (1): T5LayerCrossAttention(\n",
      "                (EncDecAttention): T5Attention(\n",
      "                  (q): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (k): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (v): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (o): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                )\n",
      "                (layer_norm): T5LayerNorm()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (2): T5LayerFF(\n",
      "                (DenseReluDense): T5DenseGatedActDense(\n",
      "                  (wi_0): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=768, out_features=2048, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=2048, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (wi_1): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=768, out_features=2048, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=2048, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (wo): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=2048, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=2048, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (act): NewGELUActivation()\n",
      "                )\n",
      "                (layer_norm): T5LayerNorm()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1-11): 11 x T5Block(\n",
      "            (layer): ModuleList(\n",
      "              (0): T5LayerSelfAttention(\n",
      "                (SelfAttention): T5Attention(\n",
      "                  (q): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (k): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (v): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (o): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                )\n",
      "                (layer_norm): T5LayerNorm()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (1): T5LayerCrossAttention(\n",
      "                (EncDecAttention): T5Attention(\n",
      "                  (q): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (k): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (v): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (o): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                )\n",
      "                (layer_norm): T5LayerNorm()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (2): T5LayerFF(\n",
      "                (DenseReluDense): T5DenseGatedActDense(\n",
      "                  (wi_0): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=768, out_features=2048, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=2048, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (wi_1): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=768, out_features=2048, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=2048, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (wo): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=2048, out_features=768, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=2048, out_features=32, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (act): NewGELUActivation()\n",
      "                )\n",
      "                (layer_norm): T5LayerNorm()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (final_layer_norm): T5LayerNorm()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = accelerator.prepare_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\newenv\\lib\\site-packages\\transformers\\training_args.py:1483: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9adbd61ed6f45b0be9cda6d1d347cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5041, 'grad_norm': 0.800885796546936, 'learning_rate': 1.9076305220883535e-05, 'epoch': 0.02}\n",
      "{'loss': 0.3829, 'grad_norm': 0.6755754947662354, 'learning_rate': 1.807228915662651e-05, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\newenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2599, 'grad_norm': 0.7544741034507751, 'learning_rate': 1.7068273092369478e-05, 'epoch': 0.05}\n",
      "{'loss': 0.2193, 'grad_norm': 0.5226228833198547, 'learning_rate': 1.606425702811245e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "061c06225d644226b637211a6434cf5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.057217638939619064, 'eval_runtime': 2497.923, 'eval_samples_per_second': 0.281, 'eval_steps_per_second': 0.035, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\newenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1524, 'grad_norm': 0.5141634345054626, 'learning_rate': 1.5060240963855424e-05, 'epoch': 0.09}\n",
      "{'loss': 0.1414, 'grad_norm': 0.5617107152938843, 'learning_rate': 1.4056224899598394e-05, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\newenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1222, 'grad_norm': 0.5457544922828674, 'learning_rate': 1.3052208835341367e-05, 'epoch': 0.12}\n",
      "{'loss': 0.1049, 'grad_norm': 0.4674505293369293, 'learning_rate': 1.204819277108434e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fefe59d7f65489bb3c49ec2a5e3e1dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.026491636410355568, 'eval_runtime': 2512.0076, 'eval_samples_per_second': 0.28, 'eval_steps_per_second': 0.035, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\newenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.098, 'grad_norm': 0.8399213552474976, 'learning_rate': 1.104417670682731e-05, 'epoch': 0.16}\n",
      "{'loss': 0.0826, 'grad_norm': 0.3447604477405548, 'learning_rate': 1.0040160642570283e-05, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\newenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0873, 'grad_norm': 0.6760973930358887, 'learning_rate': 9.036144578313254e-06, 'epoch': 0.2}\n",
      "{'loss': 0.0756, 'grad_norm': 0.3533364534378052, 'learning_rate': 8.032128514056226e-06, 'epoch': 0.21}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bbd937c4d6446e39189239ad2e65ae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32md:\\newenv\\lib\\site-packages\\accelerate\\utils\\operations.py:158\u001b[0m, in \u001b[0;36msend_to_device\u001b[1;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# .to() doesn't accept non_blocking as kwarg\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: BatchEncoding.to() got an unexpected keyword argument 'non_blocking'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 37\u001b[0m\n\u001b[0;32m      9\u001b[0m trainer \u001b[38;5;241m=\u001b[39m transformers\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[0;32m     10\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     11\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtokenized_train_dataset,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     33\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mtransformers\u001b[38;5;241m.\u001b[39mDataCollatorForLanguageModeling(tokenizer, mlm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m     34\u001b[0m )\n\u001b[0;32m     36\u001b[0m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# silence the warnings. Please re-enable for inference!\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\newenv\\lib\\site-packages\\transformers\\trainer.py:1912\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1910\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1911\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1912\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1913\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1914\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1915\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1917\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\newenv\\lib\\site-packages\\transformers\\trainer.py:2320\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[0;32m   2318\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m-> 2320\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2321\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[1;32md:\\newenv\\lib\\site-packages\\transformers\\trainer.py:2750\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[1;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2748\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2749\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[1;32m-> 2750\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2751\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[0;32m   2753\u001b[0m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[1;32md:\\newenv\\lib\\site-packages\\transformers\\trainer.py:3606\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[1;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   3603\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   3605\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[1;32m-> 3606\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3607\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3608\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3609\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[0;32m   3610\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[0;32m   3611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   3612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3614\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3616\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[0;32m   3617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[1;32md:\\newenv\\lib\\site-packages\\transformers\\trainer.py:3781\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   3778\u001b[0m observed_num_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   3780\u001b[0m \u001b[38;5;66;03m# Main evaluation loop\u001b[39;00m\n\u001b[1;32m-> 3781\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[0;32m   3782\u001b[0m     \u001b[38;5;66;03m# Update the observed num examples\u001b[39;00m\n\u001b[0;32m   3783\u001b[0m     observed_batch_size \u001b[38;5;241m=\u001b[39m find_batch_size(inputs)\n\u001b[0;32m   3784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m observed_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\newenv\\lib\\site-packages\\accelerate\\data_loader.py:463\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;66;03m# But we still move it to the device so it is done before `StopIteration` is reached\u001b[39;00m\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 463\u001b[0m         current_batch \u001b[38;5;241m=\u001b[39m \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_non_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    464\u001b[0m     next_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(dataloader_iter)\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_batches:\n",
      "File \u001b[1;32md:\\newenv\\lib\\site-packages\\accelerate\\utils\\operations.py:160\u001b[0m, in \u001b[0;36msend_to_device\u001b[1;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39mnon_blocking)\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# .to() doesn't accept non_blocking as kwarg\u001b[39;00m\n\u001b[1;32m--> 160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# `torch.Tensor.to(<int num>)` is not supported by `torch_npu` (see this [issue](https://github.com/Ascend/pytorch/issues/16)).\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# This call is inside the try-block since is_npu_available is not supported by torch.compile.\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_npu_available():\n",
      "File \u001b[1;32md:\\newenv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:801\u001b[0m, in \u001b[0;36mBatchEncoding.to\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;66;03m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001b[39;00m\n\u001b[0;32m    798\u001b[0m \u001b[38;5;66;03m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001b[39;00m\n\u001b[0;32m    799\u001b[0m \u001b[38;5;66;03m# into a HalfTensor\u001b[39;00m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m is_torch_device(device) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m--> 801\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m    802\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    803\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to cast a BatchEncoding to type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(device)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\newenv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:801\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;66;03m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001b[39;00m\n\u001b[0;32m    798\u001b[0m \u001b[38;5;66;03m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001b[39;00m\n\u001b[0;32m    799\u001b[0m \u001b[38;5;66;03m# into a HalfTensor\u001b[39;00m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m is_torch_device(device) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m--> 801\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m {k: \u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m    802\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    803\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to cast a BatchEncoding to type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(device)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from datetime import datetime\n",
    "\n",
    "project = \"medical-finetune\"\n",
    "base_model_name = \"flan-t5-base\"\n",
    "run_name = base_model_name + \"-\" + project\n",
    "output_dir = \"./\" + run_name\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    args=transformers.TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        warmup_steps=2,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=1,\n",
    "        gradient_checkpointing=True,\n",
    "        max_steps=500,\n",
    "        learning_rate=2e-5, # Want a small lr for finetuning\n",
    "        bf16=True,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        logging_steps=25,              # When to start reporting loss\n",
    "        logging_dir=\"./logs\",        # Directory for storing logs\n",
    "        save_strategy=\"steps\",       # Save the model checkpoint every logging step\n",
    "        save_steps=50,                # Save checkpoints every 50 steps\n",
    "        evaluation_strategy=\"steps\", # Evaluate the model every logging step\n",
    "        eval_steps=100,               # Evaluate and save checkpoints every 50 steps\n",
    "        do_eval=True,                # Perform evaluation at the end of training\n",
    "        report_to=\"wandb\",           # Comment this out if you don't want to use weights & baises\n",
    "        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"          # Name of the W&B run (optional)\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17cf4899e0c84451a6914d3fcd7a8330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "hf_api_key = os.getenv('HUGGINGFACE_API_KEY')\n",
    "\n",
    "login(token=hf_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a49b5e0c2440b0ab1db2b88ce20887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/54.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f391ad6800724a389b7118bca297c647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\newenv\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Siddharth\\.cache\\huggingface\\hub\\models--siddharth-magesh--flan-t5-base-medical-finetune. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/siddharth-magesh/flan-t5-base-medical-finetune/commit/8476d4377fc2682fb78916d54420b165eec17711', commit_message='Upload tokenizer', commit_description='', oid='8476d4377fc2682fb78916d54420b165eec17711', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub('siddharth-magesh/flan-t5-base-medical-finetune')\n",
    "tokenizer.push_to_hub('siddharth-magesh/flan-t5-base-medical-finetune')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
